accelerator: gpu
alias: tsmixerx_wlpr
batch_size: 16
dataloader_kwargs:
  num_workers: 0
  pin_memory: false
devices: 1
drop_last_loader: false
dropout: 0.1
early_stop_patience_steps: 50
enable_model_summary: false
exclude_insample_y: false
ff_dim: 64
futr_exog_list:
- month_sin
- month_cos
- time_idx
- type_prod
- type_inj
- inj_wwir_weighted
- inj_wwir_weighted_lag1
- inj_wwir_weighted_lag3
- inj_wwir_weighted_lag6
- inj_wwir_weighted_roll3
- inj_wwir_weighted_roll6
- inj_wwit_diff_weighted
- inj_wwit_diff_weighted_lag1
- wwir_lag1
- wwir_lag3
- wwir_lag6
- wwir_roll3
- wwir_roll6
- wwit_diff_lag1
gradient_clip_val: 1.0
h: 6
h_train: 1
hist_exog_list:
- wlpt
- womt
- womr
- wwir
- wwit
- wthp
- wbhp
- wlpt_diff
- womt_diff
- wwit_diff
- inj_wwir_weighted
- inj_wwir_weighted_lag1
- inj_wwir_weighted_lag3
- inj_wwir_weighted_lag6
- inj_wwir_weighted_roll3
- inj_wwir_weighted_roll6
- inj_wwit_diff_weighted
- inj_wwit_diff_weighted_lag1
- wwir_lag1
- wwir_lag3
- wwir_lag6
- wwir_roll3
- wwir_roll6
- wwit_diff_lag1
inference_input_size: 48
inference_windows_batch_size: 64
input_size: 48
learning_rate: 0.0005
log_every_n_steps: 10
loss: !!python/object:__main__.PhysicsInformedLoss
  _backward_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _backward_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _buffers: !!python/object/apply:collections.OrderedDict
  - []
  _context: null
  _forward_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _forward_hooks_always_called: !!python/object/apply:collections.OrderedDict
  - []
  _forward_hooks_with_kwargs: !!python/object/apply:collections.OrderedDict
  - []
  _forward_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _forward_pre_hooks_with_kwargs: !!python/object/apply:collections.OrderedDict
  - []
  _is_full_backward_hook: null
  _load_state_dict_post_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _load_state_dict_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _modules: !!python/object/apply:collections.OrderedDict
  - - - base_loss
      - !!python/object:neuralforecast.losses.pytorch.HuberLoss
        _backward_hooks: !!python/object/apply:collections.OrderedDict
        - []
        _backward_pre_hooks: !!python/object/apply:collections.OrderedDict
        - []
        _buffers: !!python/object/apply:collections.OrderedDict
        - []
        _forward_hooks: !!python/object/apply:collections.OrderedDict
        - []
        _forward_hooks_always_called: !!python/object/apply:collections.OrderedDict
        - []
        _forward_hooks_with_kwargs: !!python/object/apply:collections.OrderedDict
        - []
        _forward_pre_hooks: !!python/object/apply:collections.OrderedDict
        - []
        _forward_pre_hooks_with_kwargs: !!python/object/apply:collections.OrderedDict
        - []
        _is_full_backward_hook: null
        _load_state_dict_post_hooks: !!python/object/apply:collections.OrderedDict
        - []
        _load_state_dict_pre_hooks: !!python/object/apply:collections.OrderedDict
        - []
        _modules: !!python/object/apply:collections.OrderedDict
        - []
        _non_persistent_buffers_set: !!set {}
        _parameters: !!python/object/apply:collections.OrderedDict
        - []
        _state_dict_hooks: !!python/object/apply:collections.OrderedDict
        - []
        _state_dict_pre_hooks: !!python/object/apply:collections.OrderedDict
        - []
        delta: 1.0
        horizon_weight: null
        is_distribution_output: false
        output_names: &id001
        - ''
        outputsize_multiplier: 1
        training: true
  _non_persistent_buffers_set: !!set {}
  _parameters: !!python/object/apply:collections.OrderedDict
  - []
  _state_dict_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _state_dict_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  damping: 0.01
  feature_names:
  - inj_wwir_weighted
  horizon_weight: null
  injection_coefficient: 0.08
  is_distribution_output: false
  latest_terms: {}
  output_names: *id001
  outputsize_multiplier: 1
  physics_weight: 0.2
  smoothing_weight: 0.0
  training: true
lr_scheduler: !!python/name:torch.optim.lr_scheduler.OneCycleLR ''
lr_scheduler_kwargs:
  anneal_strategy: cos
  div_factor: 10.0
  max_lr: 0.005
  pct_start: 0.3
  total_steps: 250
max_steps: 250
n_block: 2
n_samples: 100
n_series: 13
num_lr_decays: 2
optimizer: !!python/name:torch.optim.adamw.AdamW ''
optimizer_kwargs:
  betas: !!python/tuple
  - 0.9
  - 0.99
  weight_decay: 0.0001
precision: 16-mixed
random_seed: 42
revin: true
scaler_type: standard
start_padding_enabled: false
stat_exog_list:
- x
- y
- z
step_size: 1
training_data_availability_threshold: 0.1
val_check_steps: 20
valid_batch_size: 32
valid_loss: !!python/object:neuralforecast.losses.pytorch.SMAPE
  _backward_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _backward_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _buffers: !!python/object/apply:collections.OrderedDict
  - []
  _forward_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _forward_hooks_always_called: !!python/object/apply:collections.OrderedDict
  - []
  _forward_hooks_with_kwargs: !!python/object/apply:collections.OrderedDict
  - []
  _forward_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _forward_pre_hooks_with_kwargs: !!python/object/apply:collections.OrderedDict
  - []
  _is_full_backward_hook: null
  _load_state_dict_post_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _load_state_dict_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _modules: !!python/object/apply:collections.OrderedDict
  - []
  _non_persistent_buffers_set: !!set {}
  _parameters: !!python/object/apply:collections.OrderedDict
  - []
  _state_dict_hooks: !!python/object/apply:collections.OrderedDict
  - []
  _state_dict_pre_hooks: !!python/object/apply:collections.OrderedDict
  - []
  horizon_weight: null
  is_distribution_output: false
  output_names:
  - ''
  outputsize_multiplier: 1
  training: true
windows_batch_size: 64
