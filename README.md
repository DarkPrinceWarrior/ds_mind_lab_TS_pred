# WLPR Pipeline

Пайплайн из директории `src/wlpr_pipeline.py` строит полноценный процесс прогнозирования дебита жидкости (WLPR) для фонда добывающих скважин. Ниже приводится последовательное описание всех этапов, включая подготовку входных данных, моделирование влияния нагнетательных скважин, конфигурацию модели TSMixerx, процедуру walk-forward валидации и сохранение артефактов.

---

## 1. Подготовка входных данных

Пайплайн ожидает три файла (пути задаются аргументами командной строки):

1. **Основной датасет (`--data-path`, CSV, по умолчанию `MODEL_22.09.25.csv`)**
   - Разделитель — `;`.
   - Обязательные столбцы: `DATA`, `TYPE`, `WELL` и измеряемые параметры (например, `WLPR`, `WWIR`, `WWIT`, `WLPT`, `WOMT`, `WOMR`, `WTHP`, `WBHP`).
   - `TYPE`: тип записи (`PROD` — добывающая, `INJ` — нагнетательная). Пайплайн приводит строки к верхнему регистру и убирает пробелы.
   - `DATA`: дата (дд.мм.гггг). Преобразуется в `datetime`, ошибки конвертации фильтруются.
   - Числовые столбцы приводятся к `float`, нечисловые значения превращаются в `NaN` и далее обрабатываются.
   - Пустые строки, дубликаты `(WELL, DATA)` удаляются. Строки, где нет даты или идентификатора скважины, отбрасываются.

2. **Координаты скважин (`--coords-path`, текстовый файл, по умолчанию `coords.txt`)**
   - Формат: `<WELL> <X> <Y> <Z>` на строку.
   - Допускаются комментарии (`--` в начале) и пустые строки.
   - Внутри `load_coordinates` уделяется внимание чистке идентификаторов (трим, перевод в строку) и преобразованию координат в `float`.

3. **Матрица расстояний (`--distances-path`, Excel, по умолчанию `well_distances.xlsx`)**
   - Индексы/столбцы — идентификаторы скважин (могут быть числовыми или строковыми). Функция `load_distance_matrix` приводит их к строкам, сортирует и приводит значения в числовой формат.
   - Если бронежесткий файл отсутствует или не задан, пайплайн через лог предупреждает, что переключается на расчёт расстояний по координатам.

`--output-dir` задаёт каталог для результатов (по умолчанию `artifacts`). Все артефакты, включая CSV, JSON и PDF, складываются туда.

---

## 2. Конфигурация `PipelineConfig`

Главные параметры:

- **Горизонт**: `horizon=6`, `val_horizon=6` — прогноз на полгода вперёд, столько же используется для валидации.
- **Частота**: `freq="MS"` — месячные данные, используется для реиндексации и генерации дат.
- **Минимальная история**: `min_history=60` — пропускаем короткие ряды.
- **TSMixerx**: компактный конфиг (`input_size=48`, `n_block=2`, `ff_dim=64`, `dropout=0.1`). Оптимизатор — AdamW, шедулер — OneCycleLR.
- **Нормализация**: `scaler_type="standard"`, что задаёт стандартизацию (`mean=0`, `std=1`).
- **Функции потерь**: обучение — HuberLoss (устойчив к выбросам), валидация — SMAPE (процентная ошибка).
- **Walk-forward**: 6 фолдов, шаг 6 месяцев (`cv_enabled=True`, `cv_folds=6`, `cv_step=6`).
- **Контроль качества окон**: `training_data_availability_threshold=0.1` — отбрасываем окна с менее чем 10% валидных точек.
- **Dataloader**: `num_workers=0`, `pin_memory=False` — минимальные накладные расходы при небольшом массиве данных.

Все поля можно менять напрямую в классе `PipelineConfig`.

---

## 3. Формирование данных и инжекционных признаков

### 3.1. Отбор и реиндексация рядов

1. `get_target_wells` выбирает только добывающие скважины (`TYPE=PROD`), у которых есть не менее `max(horizon+val_horizon, min_history)` наблюдений.
2. `reindex_series` по каждой скважине создаёт непрерывный ряд с шагом `freq` между первой и последней датой; пропуски заполняются `NaN`.
3. `impute_numeric` выполняет `ffill`/`bfill` по каждой скважине для числовых колонок и затем заменяет оставшиеся `NaN` на 0.
4. Пайплайн добавляет календарные и категориальные признаки: `type_prod`, `type_inj`, `month_sin`, `month_cos`, `time_idx` (порядковый номер точки).

### 3.2. Учёт влияния нагнетательных скважин

`build_injection_features` реализует несколько шагов:

1. **Выделение нагнетательных скважин**: фильтрация по `TYPE="INJ"`, очистка дат/идентификаторов, сортировка, удаление дублей.
2. **Готовим временные матрицы**: из нагнетательных рядов строятся широкие таблицы `rate_wide` (WWIR) и `diff_wide` (WWIT_DIFF) с индексом по дате и столбцами по скважинам.
3. **Расчёт расстояний**:
   - Если задана матрица `well_distances.xlsx`, используется значение `[prod, inj]` или `[inj, prod]` (симметрично).
   - Если в матрице отсутствует пара, моделируем расстояние как евклидово между координатами (`sqrt((x1-x2)^2 + ... )`).
   - Для отсутствующих координат выбрасывается исключение — без координат и матрицы влияние посчитать нельзя.
4. **Формирование весов**:
   - Для каждой пары (добывающая, нагнетательная) вычисляется вес `1 / dist^2` (обратный квадрат расстояния). Если расстояние нулевое или extremely small, используется `EPSILON`, чтобы избежать деления на ноль.
   - Веса нормируются по каждой добывающей скважине так, чтобы сумма была 1.
5. **Смешивание влияния**:
   - Вектор весов `(n_inj)` умножается на матрицы расходов `(date × inj)` → получаем «взвешенный дебит нагнеталки» для каждой добывающей скважины (`inj_wwir_weighted`).
   - Аналогично для `WWIT_DIFF` (`inj_wwit_diff_weighted`).
6. **Лаги и скользящие средние**:
   - `add_lag_features` создаёт лаги (1,3,6 месяцев) для инъекционных и гидродинамических признаков (например, `inj_wwir_weighted_lag1`, `wwir_lag3`).
   - `add_rolling_features` добавляет скользящие средние (окна 3 и 6 месяцев) для тех же показателей.
7. **Объединение**: итоговые признаки мерджатся с добывающими рядами по `(well/date)`. Если нет данных — заполняем нулями.

### 3.3. Финальный разбиение

После обогащения данных пайплайн разделяет ряд на `train_df`, `test_df` и `futr_df`:

- `train_df`: все точки до `test_start`, где `test_start` = минимальная из максимальных дат по скважинам минус `horizon-1` месяцев.
- `test_df`: `horizon` точек на каждой скважине.
- `futr_df`: набор будущих экзогенных признаков на период теста (используется при прогнозе).
- `static_df`: координаты, переименованные в `unique_id` (требование TSMixerx для статических признаков).

---

## 4. Walk-forward валидация

1. `generate_walk_forward_splits`:
   - По каждой скважине считаем максимум `time_idx` и выбираем минимальное (общий max по всем). Это обеспечивает одинаковую длину до конца.
   - Проверяем, что доступной «прошлой» истории достаточно для `folds`, `step`, `horizon`. В противном случае выбрасываем ошибку.
   - Для каждого фолда рассчитываем индексы train/val (`train_cutoff`, `val_start`, `val_end`) и извлекаем соответствующие подмножества.
2. `run_walk_forward_validation`:
   - Для каждого фолда создаётся модель (`_create_model`), инициализируется `NeuralForecast` с частотой `freq`.
   - Обучаем модель на `train_df` фолда. Валидационный горизонт задаётся `val_horizon` (6 месяцев).
   - После обучения прогнозируем на `val_df` (используя `futr_exog` и `static_df`). Результат приводится к формату с колонкой `y_hat`.
   - `evaluate_predictions` рассчитывает метрики (MAE, RMSE, SMAPE, WMAPE, MASE) по общей выборке и по отдельным скважинам.
   - Накапливаем метрики и весим их по количеству обзёрваций, чтобы получить агрегированные показатели.

Результаты walk-forward сохраняются в `cv_metrics.json`.

---

## 5. Финальное обучение и прогноз

1. **Обучение на полной выборке**: `train_and_forecast` берёт `train_df`, `static_df`, инициализирует модель и вызывает `fit` (как и во время валидации).
2. **Формирование прогнозов**: `predict` получает `futr_df` (будущие экзогенные признаки) и `static_df`. Так модель знает, какие инъекционные лаги и календарные признаки использовать при генерации точек на горизонте.
3. **Постобработка**: Колонка `tsmixerx_wlpr` переименовывается в `y_hat`, что согласовано с функцией оценки.
4. **Оценка**: `evaluate_predictions` объединяет прогноз с фактом (`test_df`) и вычисляет метрики.

---

## 6. Логирование и артефакты

- Основной логгер выводит информацию о количестве строк/скважин, конфигурации CV, метриках фолдов и итоговой точности.
- Артефакты:
  - `wlpr_predictions.csv`: прогноз `y_hat` по каждому `unique_id` и дате.
  - `metrics.json`: итоговые метрики.
  - `metadata.json`: конфигурация, список скважин, даты появления теста, ссылки на PDF.
  - `cv_metrics.json`: подробности walk-forward (если `cv_enabled=True`).
  - PDF-отчёты (`wlpr_forecasts.pdf`, `wlpr_full_history.pdf`, `wlpr_residuals.pdf`) со сравнением факта/прогноза, выделением зон Train/Val/Test и текстовыми блоками с метриками у каждой скважины.

---

## 7. Расширение и настройка

- На уровне конфигурации можно изменять количество блоков, размерность, dropout, лоссы, шедулер, шаги и т.д.
- Для ускорения тестов отключайте CV, уменьшайте `max_steps` и/или уменьшайте `ff_dim`.
- Для дополнительного учёта нагнетателей можно расширять список признаков в `hist_exog`/`futr_exog` и дополнить функцию вычисления весов (например, учитывать угол поворота, не только расстояние).
- Имеет смысл интегрировать пайплайн в планировщики (Airflow/Prefect), добавив поддержку расчёта конфига из YAML/JSON.

README описывает весь цикл: загрузка данных → подготовка и формирование признаков → учёт влияния нагнетателей → walk-forward валидация → финальное обучение → оценка и визуализация → сохранение результатов.
