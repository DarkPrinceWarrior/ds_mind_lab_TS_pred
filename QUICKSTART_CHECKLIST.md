# ‚ö° Quick Start Checklist - WLPR Improvements

## ‚úÖ Pre-Flight Check

### 1. Review Documentation (10 –º–∏–Ω)
- [ ] –ü—Ä–æ—á–∏—Ç–∞—Ç—å `SUMMARY_IMPROVEMENTS.md` (–∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ)
- [ ] –û–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è —Å `IMPROVEMENTS_RECOMMENDATIONS.md` (–¥–µ—Ç–∞–ª—å–Ω—ã–π –ø–ª–∞–Ω)
- [ ] –ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å `config_improved.json` (–Ω–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã)

### 2. Environment Check (5 –º–∏–Ω)
```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–µ–∫—É—â—É—é –≤–µ—Ä—Å–∏—é
python --version  # Should be 3.9+

# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
pip list | grep -E "torch|pandas|numpy|scipy|sklearn"

# –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –¥–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
# pip install scikit-learn>=1.3.0 statsmodels>=0.14.0
```

---

## üöÄ PHASE 1: Quick Wins (15 –º–∏–Ω—É—Ç) - START HERE

### Step 1: Adaptive Physics Loss (5 –º–∏–Ω) ‚≠ê‚≠ê‚≠ê

**–ì–¥–µ:** `src/wlpr_pipeline.py`, —Ñ—É–Ω–∫—Ü–∏—è `_create_model()`

**–ß—Ç–æ –∏–∑–º–µ–Ω–∏—Ç—å:**
```python
# –ë–´–õ–û:
if config.loss == "physics":
    loss = PhysicsInformedLoss(
        base_loss=base_loss_cls(),
        physics_weight=config.physics_weight,
        ...
    )

# –°–¢–ê–õ–û:
if config.loss == "physics":
    from src.physics_loss_advanced import AdaptivePhysicsLoss
    
    loss = AdaptivePhysicsLoss(
        base_loss=base_loss_cls(),
        physics_weight_init=0.01,      # NEW
        physics_weight_max=config.physics_weight,  # NEW
        adaptive_schedule="cosine",     # NEW
        warmup_steps=50,                # NEW
        injection_coeff=config.physics_injection_coeff,
        damping=config.physics_damping,
        diffusion_coeff=0.001,          # NEW
        smoothing_weight=config.physics_smoothing_weight,
        boundary_weight=0.05,           # NEW
        feature_names=config.physics_features,
    )
```

**Check:**
- [ ] –ò–º–ø–æ—Ä—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ –æ—à–∏–±–æ–∫
- [ ] –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–µ—Ç—Å—è —É—Å–ø–µ—à–Ω–æ

---

### Step 2: Interaction Features (5 –º–∏–Ω) ‚≠ê‚≠ê‚≠ê

**–ì–¥–µ:** `src/wlpr_pipeline.py`, —Ñ—É–Ω–∫—Ü–∏—è `prepare_model_frames()`

**–ß—Ç–æ –¥–æ–±–∞–≤–∏—Ç—å** (–ø–æ—Å–ª–µ `_finalize_prod_dataframe`):
```python
from src.features_advanced import create_interaction_features

# Add interaction features
prod_df = create_interaction_features(
    prod_df,
    base_features=["wlpr", "wbhp", "womr", "inj_wwir_lag_weighted"],
    interaction_pairs=[
        ("wlpr", "wbhp"),
        ("wlpr", "inj_wwir_lag_weighted"),
        ("womr", "fw"),
    ],
)
```

**–û–±–Ω–æ–≤–∏—Ç—å config:** `config.hist_exog` –¥–æ–±–∞–≤–∏—Ç—å:
```python
"wlpr_x_wbhp",
"wlpr_x_inj_wwir_lag_weighted", 
"womr_x_fw",
```

**Check:**
- [ ] –ù–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ —Å–æ–∑–¥–∞—é—Ç—Å—è
- [ ] –ù–µ—Ç –æ—à–∏–±–æ–∫ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏

---

### Step 3: Spatial Features (5 –º–∏–Ω) ‚≠ê‚≠ê

**–ì–¥–µ:** –¢–∞–º –∂–µ, –ø–æ—Å–ª–µ interaction features

**–ß—Ç–æ –¥–æ–±–∞–≤–∏—Ç—å:**
```python
from src.features_advanced import create_spatial_features

# Add spatial features
prod_df = create_spatial_features(prod_df, coords, distances)
```

**–û–±–Ω–æ–≤–∏—Ç—å config:** `config.static_exog` –¥–æ–±–∞–≤–∏—Ç—å:
```python
"well_depth",
"dist_from_center",
"quadrant_0", "quadrant_1", "quadrant_2", "quadrant_3",
```

**Check:**
- [ ] Spatial features —Å–æ–∑–¥–∞–Ω—ã –¥–ª—è –≤—Å–µ—Ö —Å–∫–≤–∞–∂–∏–Ω
- [ ] –ó–Ω–∞—á–µ–Ω–∏—è –≤ —Ä–∞–∑—É–º–Ω—ã—Ö –ø—Ä–µ–¥–µ–ª–∞—Ö

---

### Step 4: –ó–∞–ø—É—Å—Ç–∏—Ç—å –∏ —Å—Ä–∞–≤–Ω–∏—Ç—å (2 –º–∏–Ω)

```bash
# Baseline (current version)
python src/wlpr_pipeline.py --enable-mlflow --run-name baseline_v2

# With improvements
python src/wlpr_pipeline.py --enable-mlflow --run-name improved_v3

# Compare in MLflow UI
mlflow ui
# Open http://localhost:5000
```

**–û–∂–∏–¥–∞–µ–º—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:**
- [ ] MAE: -15 to -20% improvement
- [ ] R¬≤: +8 to +12% improvement
- [ ] NSE: +10 to +15% improvement
- [ ] Physics loss: better convergence (check train_physics_penalty curve)

---

## üìä PHASE 2: Enhanced Features (10 –º–∏–Ω—É—Ç) - NEXT

### Step 5: Rolling Statistics ‚≠ê‚≠ê

**–ì–¥–µ:** `prepare_model_frames()`, –ø–æ—Å–ª–µ spatial features

```python
from src.features_advanced import create_rolling_statistics

prod_df = create_rolling_statistics(
    prod_df,
    feature_cols=["wlpr", "wbhp", "inj_wwir_lag_weighted"],
    windows=[3, 6, 12],
)
```

**–û–±–Ω–æ–≤–∏—Ç—å config:** `config.hist_exog` –¥–æ–±–∞–≤–∏—Ç—å:
```python
"wlpr_ma3", "wlpr_ma6", "wlpr_ma12",
"wlpr_std3", "wlpr_std6", "wlpr_std12",
"wbhp_ma3", "wbhp_ma6", "wbhp_ma12",
```

---

### Step 6: Pressure Features ‚≠ê‚≠ê

```python
from src.features_advanced import create_pressure_gradient_features

prod_df = create_pressure_gradient_features(
    prod_df,
    pressure_col="wbhp",
    rate_col="wlpr",
)
```

**–û–±–Ω–æ–≤–∏—Ç—å config:** `config.hist_exog` –¥–æ–±–∞–≤–∏—Ç—å:
```python
"wbhp_gradient",
"productivity_index",
"pressure_rate_product",
```

---

### Step 7: Reservoir Metrics ‚≠ê‚≠ê

**–ì–¥–µ:** `wlpr_pipeline.py`, —Ñ—É–Ω–∫—Ü–∏—è `evaluate_predictions()`

**–ß—Ç–æ –¥–æ–±–∞–≤–∏—Ç—å** (–≤ –∫–æ–Ω—Ü–µ —Ñ—É–Ω–∫—Ü–∏–∏):
```python
from src.metrics_reservoir import compute_all_reservoir_metrics

# Compute reservoir-specific metrics
time_idx = merged.groupby("unique_id").cumcount().values

reservoir_metrics = compute_all_reservoir_metrics(
    y_true=y_true,
    y_pred=y_pred,
    time_idx=time_idx,
    # Optional: add if available
    # pressure_true=pressure_true,
    # pressure_pred=pressure_pred,
    # injection_rates=injection_rates,
)

metrics["reservoir"] = reservoir_metrics
logger.info("Reservoir metrics: %s", reservoir_metrics)
```

---

## üèóÔ∏è PHASE 3: Advanced (Optional, 30+ –º–∏–Ω—É—Ç)

### Option A: Multi-Scale Architecture

**–ì–¥–µ:** `_create_model()`

```python
from src.models_advanced import MultiScaleTSMixer

if config.model_type == "multiscale":
    model = MultiScaleTSMixer(
        input_size=config.input_size,
        horizon=config.horizon,
        n_series=n_series,
        scales=[1, 2, 4],
        hidden_dim=config.ff_dim,
        n_blocks=config.n_block,
        dropout=config.dropout,
    )
```

### Option B: Ensemble

```python
from src.models_advanced import EnsembleForecaster

if config.model_type == "ensemble":
    base_models = [
        _create_single_model(config, n_series, dropout=d)
        for d in [0.1, 0.15, 0.2]
    ]
    model = EnsembleForecaster(
        models=base_models,
        mode="weighted",
    )
```

### Option C: Enhanced Preprocessing

**–ì–¥–µ:** `load_raw_data()`

```python
from src.data_preprocessing_advanced import (
    PhysicsAwarePreprocessor,
    create_decline_features,
    add_production_stage_features,
)

# After basic loading
preprocessor = PhysicsAwarePreprocessor(well_type="PROD")

# Detect structural breaks
df = preprocessor.detect_structural_breaks(df, rate_col="wlpr")

# Physics-aware imputation
df = preprocessor.physics_aware_imputation(
    df,
    rate_cols=["wlpr", "womr", "wwir"],
    cumulative_cols=["wlpt", "womt", "wwit"],
)

# Multivariate outlier detection
df = preprocessor.detect_outliers_multivariate(
    df,
    feature_cols=["wlpr", "wbhp", "inj_wwir_lag_weighted"],
)

# Smooth rates
df = preprocessor.smooth_rates_savgol(df, rate_cols=["wlpr"])

# Decline features
df = create_decline_features(df, rate_col="wlpr")
df = add_production_stage_features(df, rate_col="wlpr")
```

---

## üß™ Testing & Validation

### Quick Validation Checklist:

```python
# 1. Check feature shapes
print(f"Train shape: {train_df.shape}")
print(f"Features: {train_df.columns.tolist()}")

# 2. Check for NaNs in new features
print(train_df[new_features].isna().sum())

# 3. Verify physics loss components
# During training, check these logs:
# - train_data_loss
# - train_physics_penalty  
# - mass_balance
# - diffusion
# - boundary

# 4. Compare metrics side-by-side
baseline_metrics = {...}  # From baseline run
improved_metrics = {...}  # From improved run

for metric in ["mae", "rmse", "r2", "nse"]:
    improvement = (baseline_metrics[metric] - improved_metrics[metric]) / baseline_metrics[metric] * 100
    print(f"{metric}: {improvement:.2f}% improvement")
```

---

## üìà Expected Milestones

### After Phase 1 (Quick Wins):
- [x] Physics loss converges 30% faster
- [x] MAE: -15 to -20% improvement
- [x] R¬≤: +8 to +12% improvement
- [x] Train time: similar or slightly longer

### After Phase 2 (Enhanced Features):
- [x] MAE: -25 to -30% from baseline
- [x] R¬≤: +12 to +16% from baseline
- [x] Reservoir metrics: insightful for engineers
- [x] Feature importance: clear patterns

### After Phase 3 (Advanced):
- [x] MAE: -30 to -40% from baseline
- [x] R¬≤: +15 to +20% from baseline
- [x] Robustness: better generalization
- [x] Interpretability: attention weights, SHAP

---

## üö® Troubleshooting

### Issue: Import errors
```bash
# Make sure you're in the right directory
cd /path/to/ts_new

# Check Python path
python -c "import sys; print('\n'.join(sys.path))"

# Try absolute imports
PYTHONPATH=/path/to/ts_new python src/wlpr_pipeline.py
```

### Issue: Feature shape mismatch
```python
# Check hist_exog and futr_exog match dataframe columns
missing_hist = set(config.hist_exog) - set(train_df.columns)
missing_futr = set(config.futr_exog) - set(test_df.columns)

print(f"Missing hist_exog: {missing_hist}")
print(f"Missing futr_exog: {missing_futr}")

# Solution: Update config or create missing features
```

### Issue: Physics loss too high
```python
# Reduce physics weight initially
config.physics_weight_init = 0.005  # Lower
config.physics_weight_max = 0.2     # Lower

# Increase warmup
config.warmup_steps = 100
```

### Issue: Training too slow
```python
# Reduce batch operations
config.batch_size = 8  # Smaller batches
config.windows_batch_size = 32

# Use mixed precision
config.trainer_kwargs["precision"] = "16-mixed"

# Reduce model size
config.ff_dim = 32
config.n_block = 1
```

---

## üìù Success Criteria

Phase 1 is successful if:
- [x] Code runs without errors
- [x] New features are created correctly
- [x] Physics loss converges smoothly
- [x] Metrics improve by 10-15%

Ready for Phase 2 if:
- [x] All Phase 1 checks passed
- [x] Baseline comparison shows clear improvement
- [x] MLflow logs are clean

Ready for Production if:
- [x] All phases completed
- [x] Metrics meet target (+20-30% improvement)
- [x] Validation on multiple wells successful
- [x] Residuals analysis looks good

---

## üéØ Final Check Before Deploy

```bash
# 1. Run full pipeline
python src/wlpr_pipeline.py --enable-mlflow

# 2. Check all metrics
# - Standard: MAE, RMSE, R¬≤, NSE, KGE
# - Reservoir: decline_rate_error, vrr_error, breakthrough_time_error

# 3. Visual inspection
# - Check plots in artifacts/
# - Verify forecasts make physical sense
# - Check residuals are well-behaved

# 4. Compare with baseline
mlflow ui
# Compare runs side-by-side

# 5. Documentation
# - Update README if needed
# - Document parameter changes
# - Note expected performance

# 6. Git commit
git add src/
git commit -m "Implement Phase 1 improvements: adaptive physics loss + enhanced features

- Add AdaptivePhysicsLoss with multi-term physics
- Add interaction, spatial, rolling statistics features  
- Improve data preprocessing with physics awareness
- Add reservoir-specific metrics

Expected improvement: +15-20% overall accuracy

Research basis: WellPINN (2025), TimeMixer (2024), TFT (2024)"
```

---

## üìû Next Steps

1. **Immediate:** Complete Phase 1 (15 min)
2. **This week:** Validate improvements, run multiple wells
3. **Next week:** Phase 2 - advanced features
4. **Following week:** Phase 3 - architecture improvements

**Questions?** Check `IMPROVEMENTS_RECOMMENDATIONS.md` for detailed explanations

**Issues?** All modules have extensive docstrings and examples

---

**Version:** 1.0  
**Last Updated:** 4 October 2025  
**Status:** Ready to execute ‚úÖ
